{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "name": "python_kubernetes",
            "display_name": "unSkript (Build: 1172)"
        },
        "language_info": {
            "name": "python",
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "pygments_lexer": "ipython3"
        },
        "execution_data": {
            "workflow_id": "3b27cdda-53d0-4063-9be5-ad6ed188d759",
            "execution_id": "e727071f-08f1-470b-8b0b-a681bc64da03",
            "notebook_id": "fcd10601-98ac-4cf0-8f7b-9cd476d0bd1d.ipynb",
            "tenant_id": "982dba5f-d9df-48ae-a5bf-ec1fc94d4882",
            "tenant_url": "https://tenant-staging.alpha.unskript.io",
            "proxy_id": "1499f27c-6406-4fbd-bd1b-c6f92800018f",
            "parameters": [
                "sitemap"
            ],
            "runbook_name": "Check Readability of website from sitemap",
            "environment_name": "Staging",
            "show_tool_tip": false,
            "search_string": "",
            "inputs_for_searched_lego": "",
            "user_email_id": "doug@unskript.com",
            "environment_type": "ENVIRONMENT_TYPE_AWS_EC2"
        },
        "parameterSchema": {
            "definitions": null,
            "properties": {
                "sitemap": {
                    "default": "https://docs.unskript.com/unskript-product-documentation/sitemap.xml",
                    "description": "url of your XML sitemap",
                    "title": "sitemap",
                    "type": "string"
                }
            },
            "required": [],
            "title": "Schema",
            "type": "object"
        },
        "outputParameterSchema": {
            "definitions": null,
            "properties": {},
            "required": [],
            "title": "Schema",
            "type": "object"
        },
        "parameterValues": {
            "sitemap": "https://docs.unskript.com/unskript-product-documentation/sitemap.xml"
        }
    },
    "cells": [
        {
            "id": "f941cf11-5e69-4258-a470-9374e97dd9a4",
            "cell_type": "code",
            "metadata": {
                "actionNeedsCredential": false,
                "actionSupportsIteration": false,
                "actionSupportsPoll": false,
                "deletable": false,
                "editable": false,
                "jupyter": {
                    "source_hidden": true
                },
                "name": "unSkript Internal",
                "orderProperties": [],
                "tags": [
                    "unSkript:nbParam"
                ],
                "title": [
                    "unSkript Internal"
                ],
                "trusted": true
            },
            "source": "import json\nimport os\nfrom unskript import nbparams\nfrom unskript.secrets import ENV_MODE, ENV_MODE_AWS\nfrom unskript.fwk.workflow import Task, Workflow\n\nenv = {\"ENV_MODE\":\"ENV_MODE_AWS\",\"TENANT_ID\":\"982dba5f-d9df-48ae-a5bf-ec1fc94d4882\",\"PROXY_ID\":\"1499f27c-6406-4fbd-bd1b-c6f92800018f\",\"TENANT_URL\":\"https://tenant-staging.alpha.unskript.io\",\"AWS_REGION\":\"us-west-2\"}\nsecret_store_cfg = {\"SECRET_STORE_TYPE\":\"SECRET_STORE_TYPE_AWS\",\"AWS_SECRET_PREFIX\":\"staging\",\"AWS_REGION\":\"us-west-2\"}\nos.environ[\"UNSKRIPT_REDIS_HOST\"] = \"redis-master.redis.svc.cluster.local\"\nos.environ[\"UNSKRIPT_TOKEN\"] = \"5c4a5754-0600-11ec-9a03-0242ac130003\"\nos.environ[\"UNSKRIPT_SIDECAR_URL\"] = \"http://sidecar.sidecar.svc.cluster.local\"\nos.environ[\"TENANT_URL\"] = env[\"TENANT_URL\"]\nparamDict = {\"sitemap\":\"https://docs.unskript.com/unskript-product-documentation/sitemap.xml\"}\nunSkriptOutputParamDict = {}\nparamDict.update(env)\nparamDict.update(secret_store_cfg)\nparamsJson = json.dumps(paramDict)\nnbParamsObj = nbparams.NBParams(paramsJson)\nsitemap = nbParamsObj.get('sitemap')\n\n\nw = Workflow(env, secret_store_cfg, None, global_vars=globals(), check_uuids=None)\n\n",
            "execution_count": 2,
            "outputs": []
        },
        {
            "id": "1f4bee13-253b-48da-8ef1-b78269cf51d7",
            "cell_type": "code",
            "metadata": {
                "customAction": true,
                "execution_data": {
                    "last_date_success_run_cell": "2023-06-13T01:19:26.341Z"
                },
                "jupyter": {
                    "source_hidden": true
                },
                "name": "pip install",
                "orderProperties": [],
                "tags": [],
                "title": "pip install",
                "trusted": true
            },
            "source": "pip install xmltodict textstat bs4",
            "execution_count": 3,
            "outputs": []
        },
        {
            "id": "188ca271-cbd4-4798-ab52-9517b457dff2",
            "cell_type": "code",
            "metadata": {
                "customAction": true,
                "execution_data": {
                    "last_date_success_run_cell": "2023-06-13T01:19:33.238Z"
                },
                "jupyter": {
                    "source_hidden": true
                },
                "name": "Read in the Sitemap",
                "orderProperties": [],
                "tags": [],
                "title": "Read in the Sitemap",
                "trusted": true
            },
            "source": "import requests\nimport xmltodict\nimport json\n\n#This Action reads in the Sitemap, converts the XML to a dictionary, \n# and then extracts every URL into a list\n\n\nresponse = requests.get(sitemap)\ncontents = response.text\n# Parse the XML data to a dictionary\nxml_dict = xmltodict.parse(contents)\n#print(xml_dict['urlset'])\nurlList = []\nfor url in xml_dict['urlset']['url']:\n    urlList.append(url['loc'])\n\nprint(\"sitemap read in, list of urls created\")\n",
            "execution_count": 4,
            "outputs": []
        },
        {
            "id": "aa1b51df-b59e-4a31-8c4e-a010c4713c18",
            "cell_type": "code",
            "metadata": {
                "customAction": true,
                "execution_data": {
                    "last_date_success_run_cell": "2023-06-13T01:25:00.096Z"
                },
                "name": "get readability for a URL",
                "orderProperties": [],
                "tags": [],
                "title": "get readability for a URL",
                "trusted": true
            },
            "source": "import requests\nimport textstat\nfrom bs4 import BeautifulSoup\n\n\nurls = urlList\nreadability = []\n\nfor url in urls:\n    # get the text of the file\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n\n    # Remove script and style elements\n    for script in soup([\"script\", \"style\"]):\n        script.decompose()\n\n    text = soup.get_text()\n    #lines = (line.strip() for line in text.splitlines())\n    #chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n    #text = \"\\n\".join(chunk for chunk in chunks if chunk)\n    #analyze the text for readability\n    fk_reading_ease = textstat.flesch_reading_ease(text)\n    flesch_kincaid_grade = textstat.flesch_kincaid_grade(text)\n    gunning_fog = textstat.gunning_fog(text)\n    automated_readability = textstat.automated_readability_index(text)\n    result = {'url': url,\"fk_reading_ease\":fk_reading_ease, \"fk_grade\": flesch_kincaid_grade, \"gf\":gunning_fog, \"automated_readability\":automated_readability}\n    readability.append(result)\nprint(\"readability stats collected for each page\")",
            "execution_count": 5,
            "outputs": []
        },
        {
            "id": "57a92435-8027-47d1-82fb-5e07e842bc65",
            "cell_type": "code",
            "metadata": {
                "execution_data": {
                    "last_date_success_run_cell": "2023-06-13T01:25:06.820Z"
                },
                "name": "create a chart",
                "orderProperties": [],
                "tags": [],
                "title": "create a chart",
                "trusted": true
            },
            "source": "#take the list into a dataframe\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n# Create a DataFrame from the list of dictionaries\ndf = pd.DataFrame(readability)\ndf.tail()\n# Convert the 'flesch_kincaid_grade' column to integers\ndf['fk_grade'] = df['fk_grade'].astype(int)\n\n# Group the DataFrame by 'fk' and count the number of URLs for each group\ncounts = df.groupby('fk_grade')['url'].count()\n\n# Create a bar chart of the counts\ncounts.plot(kind='bar')\nplt.xlabel('fk_grade')\nplt.ylabel('Number of URLs')\nplt.title('URL Count by fk grade level')\nplt.show()\n",
            "execution_count": 6,
            "outputs": []
        },
        {
            "id": "d07ac4ac-1d20-4ece-85a8-18607c2dab70",
            "cell_type": "code",
            "metadata": {
                "execution_data": {
                    "last_date_success_run_cell": "2023-06-13T01:36:55.393Z"
                },
                "orderProperties": [],
                "tags": [],
                "trusted": true
            },
            "source": "import ipywidgets as widgets\nfrom IPython.display import display\n\n#selected_rows = df[(df['fk_grade'] >= 0) & (df['fk_grade'] <= 20)]\nselected_rows = df.sort_values('fk_grade')\n# Print the URLs for the selected rows\n# Print the URLs and 'fk' values for the selected rows\n#for index, row in selected_rows.iterrows():\n#    print(f\"URL: {row['url']}, fk_grade: {row['fk_grade']}\")\n# Create a slider widget\nslider = widgets.IntRangeSlider(\n    min=0,\n    max=80,\n    step=1,\n    description='Score Range:',\n    continuous_update=True  # Set to True for continuous update while sliding\n)\n\n# Create a function to update the displayed DataFrame based on the slider value\ndef update_df_range(*args):\n    # Get the slider value\n    min_score, max_score = slider.value\n    \n    # Filter the DataFrame based on the score range\n    filtered_df = selected_rows[(selected_rows['fk_grade'] >= min_score) & (selected_rows['fk_grade'] <= max_score)]\n    # Select only the 'URL' and 'fk_grade' columns\n    filtered_df = filtered_df[['URL', 'fk_grade']]\n    # Display the filtered DataFrame\n    display(filtered_df)\n\n# Attach the function to the slider's value change event\nslider.observe(update_df_range, 'value')\n\n# Display the initial DataFrame and the slider widget\ndisplay(selected_rows)\ndisplay(slider)",
            "execution_count": 13,
            "outputs": []
        },
        {
            "id": "a5bf0c1f-5468-4f05-9ccd-7deffd6dbdb8",
            "cell_type": "code",
            "metadata": {
                "orderProperties": []
            },
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ]
}