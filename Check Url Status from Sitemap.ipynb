{
    "nbformat": 4,
    "nbformat_minor": 5,
    "metadata": {
        "kernelspec": {
            "name": "python_kubernetes",
            "display_name": "unSkript (Build: 1091)"
        },
        "language_info": {
            "name": "python",
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "pygments_lexer": "ipython3"
        },
        "execution_data": {
            "workflow_id": "0620dbf7-fee7-45a9-9280-d77174557139",
            "execution_id": "4ab91abf-a683-4f53-ba89-c60168c152c1",
            "notebook_id": "fa13684c-523c-45d3-a118-0b827a98bb39.ipynb",
            "tenant_id": "982dba5f-d9df-48ae-a5bf-ec1fc94d4882",
            "tenant_url": "https://tenant-staging.alpha.unskript.io",
            "proxy_id": "1499f27c-6406-4fbd-bd1b-c6f92800018f",
            "parameters": [
                "sitemap"
            ],
            "runbook_name": "Check Url Status from Sitemap",
            "environment_name": "Staging",
            "show_tool_tip": false,
            "search_string": "",
            "inputs_for_searched_lego": "",
            "user_email_id": "doug@unskript.com",
            "environment_type": "ENVIRONMENT_TYPE_AWS_EC2"
        },
        "parameterSchema": {
            "definitions": null,
            "properties": {
                "sitemap": {
                    "default": "https://www.unskript.com/sitemap.xml",
                    "description": "url of your XML sitemap",
                    "title": "sitemap",
                    "type": "string"
                }
            },
            "required": [],
            "title": "Schema",
            "type": "object"
        },
        "outputParameterSchema": {
            "definitions": null,
            "properties": {},
            "required": [],
            "title": "Schema",
            "type": "object"
        },
        "parameterValues": {
            "sitemap": "https://www.unskript.com/sitemap.xml"
        }
    },
    "cells": [
        {
            "id": "fdbb7be5-4df1-4e29-b2bb-9c967758fbc0",
            "cell_type": "code",
            "metadata": {
                "actionNeedsCredential": false,
                "actionSupportsIteration": false,
                "actionSupportsPoll": false,
                "deletable": false,
                "editable": false,
                "execution_data": {
                    "last_date_success_run_cell": "2023-04-27T18:23:16.809Z"
                },
                "jupyter": {
                    "source_hidden": true
                },
                "name": "unSkript Internal",
                "orderProperties": [],
                "tags": [
                    "unSkript:nbParam"
                ],
                "title": [
                    "unSkript Internal"
                ],
                "trusted": true
            },
            "source": "import json\nimport os\nfrom unskript import nbparams\nfrom unskript.secrets import ENV_MODE, ENV_MODE_AWS\nfrom unskript.fwk.workflow import Task, Workflow\n\nenv = {\"ENV_MODE\":\"ENV_MODE_AWS\",\"TENANT_ID\":\"982dba5f-d9df-48ae-a5bf-ec1fc94d4882\",\"PROXY_ID\":\"1499f27c-6406-4fbd-bd1b-c6f92800018f\",\"TENANT_URL\":\"https://tenant-staging.alpha.unskript.io\",\"AWS_REGION\":\"us-west-2\"}\nsecret_store_cfg = {\"SECRET_STORE_TYPE\":\"SECRET_STORE_TYPE_AWS\",\"AWS_SECRET_PREFIX\":\"staging\",\"AWS_REGION\":\"us-west-2\"}\nos.environ[\"UNSKRIPT_REDIS_HOST\"] = \"redis-master.redis.svc.cluster.local\"\nos.environ[\"UNSKRIPT_TOKEN\"] = \"5c4a5754-0600-11ec-9a03-0242ac130003\"\nos.environ[\"UNSKRIPT_SIDECAR_URL\"] = \"http://sidecar.sidecar.svc.cluster.local\"\nos.environ[\"TENANT_URL\"] = env[\"TENANT_URL\"]\nparamDict = {\"sitemap\": \"https://www.unskript.com/sitemap.xml\"}\nunSkriptOutputParamDict = {}\nparamDict.update(env)\nparamDict.update(secret_store_cfg)\nparamsJson = json.dumps(paramDict)\nnbParamsObj = nbparams.NBParams(paramsJson)\nsitemap = nbParamsObj.get('sitemap')\n\n\nw = Workflow(env, secret_store_cfg, None, global_vars=globals(), check_uuids=None)",
            "execution_count": 16,
            "outputs": []
        },
        {
            "id": "1f4bee13-253b-48da-8ef1-b78269cf51d7",
            "cell_type": "code",
            "metadata": {
                "customAction": true,
                "execution_data": {
                    "last_date_success_run_cell": "2023-04-27T18:23:23.292Z"
                },
                "jupyter": {
                    "source_hidden": true
                },
                "name": "pip install",
                "orderProperties": [],
                "tags": [],
                "title": "pip install",
                "trusted": true
            },
            "source": "pip install xmltodict textstat bs4",
            "execution_count": 17,
            "outputs": []
        },
        {
            "id": "188ca271-cbd4-4798-ab52-9517b457dff2",
            "cell_type": "code",
            "metadata": {
                "customAction": true,
                "execution_data": {
                    "last_date_success_run_cell": "2023-04-27T18:23:28.667Z"
                },
                "jupyter": {
                    "source_hidden": true
                },
                "name": "Read in the Sitemap",
                "orderProperties": [],
                "tags": [],
                "title": "Read in the Sitemap",
                "trusted": true
            },
            "source": "import requests\nimport xmltodict\nimport json\n\n#This Action reads in the Sitemap, converts the XML to a dictionary, \n# and then extracts every URL into a list\n\n\nresponse = requests.get(sitemap)\ncontents = response.text\n# Parse the XML data to a dictionary\nxml_dict = xmltodict.parse(contents)\n#print(xml_dict['urlset'])\nurlList = []\nfor url in xml_dict['urlset']['url']:\n    urlList.append(url['loc'])\n\nprint(\"sitemap read in, list of urls created\")\n",
            "execution_count": 18,
            "outputs": []
        },
        {
            "id": "2d42c87c-c18d-4519-8859-531e5c4a04e7",
            "cell_type": "code",
            "metadata": {
                "customAction": true,
                "execution_data": {
                    "last_date_success_run_cell": "2023-04-27T18:24:35.439Z"
                },
                "name": "Check the urls in the sitemap",
                "orderProperties": [],
                "tags": [],
                "title": "Check the urls in the sitemap",
                "trusted": true
            },
            "source": "import requests\n\nurls = urlList\n#urls = [\"https://unskript.com\"]\nsitemapResponses=[]\nfor url in urls:\n    # get the text of the file\n    response = requests.get(url)\n    data = { url: response.status_code}\n    sitemapResponses.append(data)\n    if response.status_code != 200:\n        print(url, response.status_code)",
            "execution_count": 19,
            "outputs": []
        },
        {
            "id": "aa1b51df-b59e-4a31-8c4e-a010c4713c18",
            "cell_type": "code",
            "metadata": {
                "customAction": true,
                "execution_data": {
                    "last_date_success_run_cell": "2023-04-30T23:44:03.052Z"
                },
                "name": "get all links on all pages",
                "orderProperties": [],
                "tags": [],
                "title": "get all links on all pages",
                "trusted": true
            },
            "source": "import requests\nimport textstat\nfrom bs4 import BeautifulSoup\n\n\nurls = urlList\n#urls = [\"https://unskript.com\"]\nlinks = {}\n\nfor url in urls:\n    # get the text of the file\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n    for link in soup.find_all('a'):\n        link_url = link.get('href')\n        if (link_url not in links) and (link_url[0:4] == \"http\") and (\"localhost\" not in link_url)and (\"127.0.0.1\" not in link_url) and (\"runbooks.sh\" not in link_url):\n            #print(link_url, url)\n            #we want to add it\n            link_response = requests.get(link_url)\n            link_status = link_response.status_code\n            data = {\"status\": link_status, \"first_seen\": url}\n            links[link_url] = data\nprint(\"list completed\")",
            "execution_count": 23,
            "outputs": []
        },
        {
            "id": "57a92435-8027-47d1-82fb-5e07e842bc65",
            "cell_type": "code",
            "metadata": {
                "execution_data": {
                    "last_date_success_run_cell": "2023-04-30T23:44:30.800Z"
                },
                "name": "list bad links",
                "orderProperties": [],
                "tags": [],
                "title": "list bad links",
                "trusted": true
            },
            "source": "#take the list into a dataframe\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n# Create a DataFrame from the list of dictionaries\ndf = pd.DataFrame.from_dict(links, orient='index')\ndf.tail()\n#Get all urls here status is not 200\nmask = df['status'] != 200\nfiltered_df = df[mask]\n\n# Extract the URLs from the index of the filtered DataFrame\nurls = filtered_df.index.tolist()\n\nfor index, row in filtered_df.iterrows():\n    print(index, row['status'], row['first_seen'])\n\n",
            "execution_count": 24,
            "outputs": []
        }
    ]
}